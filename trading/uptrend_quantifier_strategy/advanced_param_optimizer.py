# -*- coding: utf-8 -*-
"""
é«˜æ€§èƒ½å‚æ•°ä¼˜åŒ–å™¨ - åŸºäºMultiBacktestæ€è·¯
================================================================================
æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯ï¼š
- ğŸ§  æ™ºèƒ½å‚æ•°ç½‘æ ¼ï¼šè´å¶æ–¯ä¼˜åŒ– + è‡ªé€‚åº”ç½‘æ ¼æœç´¢
- âš¡ åˆ†å±‚ä¼˜åŒ–ï¼šç²—æœç´¢ -> ç²¾ç»†æœç´¢ï¼Œå¤§å¹…å‡å°‘è®¡ç®—é‡
- ğŸ›¡ï¸ æ—©åœæœºåˆ¶ï¼šå¿«é€Ÿæ’é™¤å·®çš„å‚æ•°ç»„åˆ
- ğŸ’¾ æ™ºèƒ½ç¼“å­˜ï¼šå‚æ•°ç»“æœè®°å¿†åŒ–ï¼Œé¿å…é‡å¤è®¡ç®—
- ğŸš€ å‘é‡åŒ–å¹¶è¡Œï¼šä¼˜åŒ–çš„å¤šè¿›ç¨‹ç­–ç•¥
- ğŸ“Š å®æ—¶ç›‘æ§ï¼šæ€§èƒ½åˆ†æå’Œè¿›åº¦é¢„æµ‹
- ğŸ¯ å‚æ•°ä¾èµ–åˆ†æï¼šè¯†åˆ«å‚æ•°ç›¸å…³æ€§ï¼Œå‡å°‘æ— æ•ˆç»„åˆ
- ğŸ’¡ è‡ªé€‚åº”é‡‡æ ·ï¼šæ ¹æ®ç»“æœåŠ¨æ€è°ƒæ•´æœç´¢ç­–ç•¥
================================================================================
"""

import os
import sys
import time
import numpy as np
import pandas as pd
from concurrent.futures import ProcessPoolExecutor, as_completed
from functools import partial, lru_cache
from typing import Dict, List, Tuple, Optional, Any, Union
import itertools
from tqdm import tqdm
from datetime import datetime
import pickle
import warnings
warnings.filterwarnings("ignore")

# Scikit-learn for advanced optimization
try:
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import ParameterGrid
    SKLEARN_AVAILABLE = True
except ImportError:
    print("âš ï¸  è­¦å‘Š: scikit-learnæœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºç¡€ä¼˜åŒ–ç®—æ³•")
    SKLEARN_AVAILABLE = False

# è®¾ç½®è·¯å¾„
script_path = os.path.abspath(__file__)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(script_path)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from backtesting import Backtest


class AdvancedParameterOptimizer:
    """
    é«˜æ€§èƒ½å‚æ•°ä¼˜åŒ–å™¨
    åŸºäºMultiBacktestæ€è·¯çš„å…¨é¢æ€§èƒ½ä¼˜åŒ–
    """
    
    def __init__(self, 
                 strategy_class,
                 data_dir: str,
                 results_dir: str,
                 start_date: Optional[str] = None,
                 end_date: Optional[str] = None,
                 max_workers: Optional[int] = None):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å™¨
        
        Parameters:
        -----------
        strategy_class : Strategyç±»
        data_dir : æ•°æ®ç›®å½•è·¯å¾„  
        results_dir : ç»“æœä¿å­˜ç›®å½•
        start_date : å¼€å§‹æ—¥æœŸ
        end_date : ç»“æŸæ—¥æœŸ
        max_workers : æœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•°
        """
        self.strategy_class = strategy_class
        self.data_dir = data_dir
        self.results_dir = results_dir
        self.start_date = start_date
        self.end_date = end_date
        self.max_workers = max_workers or min(os.cpu_count() or 4, 8)
        
        # æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
        self._setup_performance_components()
        
        # æ•°æ®ç¼“å­˜
        self._data_cache = {}
        self._param_cache = {}
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            'total_backtests': 0,
            'cache_hits': 0,
            'early_stops': 0,
            'start_time': None,
            'phase_times': {}
        }
    
    def _setup_performance_components(self):
        """
        è®¾ç½®æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
        """
        # åˆ›å»ºç»“æœç›®å½•
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.run_dir = os.path.join(
            self.results_dir, 
            f"{self.strategy_class.__name__}_advanced_opt_{timestamp}"
        )
        os.makedirs(self.run_dir, exist_ok=True)
        
        # åŠ è½½æ•°æ®æ–‡ä»¶åˆ—è¡¨
        self.csv_files = [f for f in os.listdir(self.data_dir) if f.endswith('.csv')]
        print(f"ğŸ“ å‘ç° {len(self.csv_files)} ä¸ªæ•°æ®æ–‡ä»¶")
        
        # åˆå§‹åŒ–è´å¶æ–¯ä¼˜åŒ–ç»„ä»¶
        if SKLEARN_AVAILABLE:
            self.gp_regressor = None
            self.scaler = StandardScaler()
            self.param_history = []
            self.score_history = []
    
    @lru_cache(maxsize=1000)
    def _load_cached_data(self, filepath: str) -> Optional[pd.DataFrame]:
        """
        ç¼“å­˜æ•°æ®åŠ è½½ï¼Œé¿å…é‡å¤è¯»å–
        """
        cache_key = (filepath, self.start_date, self.end_date)
        
        if cache_key in self._data_cache:
            return self._data_cache[cache_key]
        
        try:
            data = pd.read_csv(filepath, index_col='Date', parse_dates=True)
            
            # æ—¥æœŸè¿‡æ»¤
            if self.start_date:
                data = data[data.index >= pd.to_datetime(self.start_date)]
            if self.end_date:
                data = data[data.index <= pd.to_datetime(self.end_date)]
            
            # æ•°æ®æ¸…ç†
            data = data.rename(columns={
                'open': 'Open', 'high': 'High', 
                'low': 'Low', 'close': 'Close', 'volume': 'Volume'
            })
            
            required_cols = ['Open', 'High', 'Low', 'Close']
            if not all(col in data.columns for col in required_cols):
                return None
                
            data = data.dropna(subset=required_cols)
            
            if len(data) < 50:
                return None
            
            # ç¼“å­˜æ•°æ®
            self._data_cache[cache_key] = data
            return data
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ {filepath}: {e}")
            return None
    
    def _hash_params(self, params: Dict) -> str:
        """
        ç”Ÿæˆå‚æ•°å“ˆå¸Œï¼Œç”¨äºç¼“å­˜
        """
        return str(sorted(params.items()))
    
    def _run_single_backtest(self, filepath: str, params: Dict) -> Optional[Dict]:
        """
        è¿è¡Œå•ä¸ªå›æµ‹ï¼Œå¸¦ç¼“å­˜ä¼˜åŒ–
        """
        # æ£€æŸ¥å‚æ•°ç¼“å­˜
        param_hash = self._hash_params(params)
        cache_key = (filepath, param_hash)
        
        if cache_key in self._param_cache:
            self.performance_stats['cache_hits'] += 1
            return self._param_cache[cache_key]
        
        # åŠ è½½æ•°æ®
        data = self._load_cached_data(filepath)
        if data is None:
            return None
        
        try:
            # åˆ›å»ºå›æµ‹å®ä¾‹
            bt = Backtest(data, self.strategy_class,
                         cash=100000, commission=0.002,
                         exclusive_orders=True, trade_on_close=True)
            
            # è¿è¡Œå›æµ‹
            stats = bt.run(**params)
            
            # æå–å…³é”®æŒ‡æ ‡
            result = {
                'Stock': os.path.splitext(os.path.basename(filepath))[0],
                'Sharpe Ratio': float(stats.get('Sharpe Ratio', 0)),
                'Return [%]': float(stats.get('Return [%]', 0)),
                'Max. Drawdown [%]': float(stats.get('Max. Drawdown [%]', 0)),
                '# Trades': int(stats.get('# Trades', 0)),
                'Win Rate [%]': float(stats.get('Win Rate [%]', 0)),
                'Profit Factor': float(stats.get('Profit Factor', 0))
            }
            
            # ç¼“å­˜ç»“æœ
            self._param_cache[cache_key] = result
            self.performance_stats['total_backtests'] += 1
            
            return result
            
        except Exception as e:
            print(f"âŒ å›æµ‹å¤±è´¥ {filepath} with {params}: {e}")
            return None
    
    def _evaluate_param_set(self, params: Dict) -> float:
        """
        è¯„ä¼°å‚æ•°ç»„åˆï¼Œè¿”å›ç»¼åˆå¾—åˆ†
        """
        results = []
        
        # å¹¶è¡Œè¿è¡Œæ‰€æœ‰æ–‡ä»¶çš„å›æµ‹
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            for csv_file in self.csv_files:
                filepath = os.path.join(self.data_dir, csv_file)
                future = executor.submit(self._run_single_backtest, filepath, params)
                futures.append(future)
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(futures):
                result = future.result(timeout=30)
                if result is not None:
                    results.append(result)
        
        if not results:
            return -999.0  # æ— æ•ˆå‚æ•°ç»„åˆçš„æƒ©ç½šåˆ†æ•°
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        df = pd.DataFrame(results)
        
        # å¤šæŒ‡æ ‡ç»¼åˆè¯„åˆ†
        sharpe_mean = df['Sharpe Ratio'].mean()
        return_mean = df['Return [%]'].mean()
        drawdown_mean = abs(df['Max. Drawdown [%]'].mean())
        trades_mean = df['# Trades'].mean()
        
        # ç»¼åˆå¾—åˆ†å…¬å¼ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´æƒé‡ï¼‰
        score = (
            0.4 * sharpe_mean +           # 40% å¤æ™®æ¯”ç‡
            0.3 * (return_mean / 100) +   # 30% æ”¶ç›Šç‡
            0.2 * (1 / (1 + drawdown_mean / 100)) +  # 20% å›æ’¤æƒ©ç½š
            0.1 * min(trades_mean / 10, 1.0)  # 10% äº¤æ˜“é¢‘ç‡ï¼ˆé€‚ä¸­ä¸ºå¥½ï¼‰
        )
        
        return score
    
    def _early_stop_check(self, current_score: float, best_score: float, threshold: float = -0.5) -> bool:
        """
        æ—©åœæ£€æŸ¥ï¼šå¦‚æœå½“å‰å¾—åˆ†æ˜æ˜¾ä½äºæœ€ä½³å¾—åˆ†ï¼Œæå‰ç»ˆæ­¢
        """
        if best_score > 0 and current_score < best_score + threshold:
            self.performance_stats['early_stops'] += 1
            return True
        return False
    
    def _generate_smart_grid(self, param_ranges: Dict, initial_points: int = 20) -> List[Dict]:
        """
        æ™ºèƒ½å‚æ•°ç½‘æ ¼ç”Ÿæˆ
        ç¬¬ä¸€é˜¶æ®µï¼šç¨€ç–é‡‡æ ·æ‰¾åˆ°å¥½çš„åŒºåŸŸ
        """
        print("ğŸ§  ç”Ÿæˆæ™ºèƒ½å‚æ•°ç½‘æ ¼...")
        
        # ç”Ÿæˆåˆå§‹ç¨€ç–ç½‘æ ¼
        sparse_grid = []
        
        for _ in range(initial_points):
            params = {}
            for param_name, param_range in param_ranges.items():
                if isinstance(param_range, range):
                    params[param_name] = np.random.choice(list(param_range))
                elif isinstance(param_range, (list, tuple)):
                    params[param_name] = np.random.choice(param_range)
                else:
                    # å‡è®¾æ˜¯æ•°å€¼èŒƒå›´
                    params[param_name] = np.random.uniform(param_range[0], param_range[1])
            sparse_grid.append(params)
        
        return sparse_grid
    
    def _bayesian_optimization(self, param_ranges: Dict, n_calls: int = 50) -> List[Tuple[Dict, float]]:
        """
        è´å¶æ–¯ä¼˜åŒ–ï¼ˆéœ€è¦scikit-learnï¼‰
        """
        if not SKLEARN_AVAILABLE:
            print("âš ï¸  è·³è¿‡è´å¶æ–¯ä¼˜åŒ–ï¼šéœ€è¦scikit-learn")
            return []
        
        print("ğŸ¯ å¼€å§‹è´å¶æ–¯ä¼˜åŒ–...")
        
        # åˆå§‹åŒ–å‚æ•°ç©ºé—´
        param_names = list(param_ranges.keys())
        param_bounds = []
        
        for param_name in param_names:
            param_range = param_ranges[param_name]
            if isinstance(param_range, range):
                param_bounds.append((min(param_range), max(param_range)))
            elif isinstance(param_range, (list, tuple)):
                param_bounds.append((min(param_range), max(param_range)))
        
        # è´å¶æ–¯ä¼˜åŒ–ä¸»å¾ªç¯
        results = []
        best_score = -np.inf
        
        for i in range(n_calls):
            if i < 5:
                # å‰å‡ æ¬¡éšæœºé‡‡æ ·
                params = {}
                for j, param_name in enumerate(param_names):
                    low, high = param_bounds[j]
                    params[param_name] = np.random.uniform(low, high)
            else:
                # ä½¿ç”¨é«˜æ–¯è¿‡ç¨‹é¢„æµ‹
                if self.gp_regressor is None:
                    kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))
                    self.gp_regressor = GaussianProcessRegressor(kernel=kernel, alpha=1e-6)
                
                # è®­ç»ƒæ¨¡å‹
                X = np.array(self.param_history)
                y = np.array(self.score_history)
                
                X_scaled = self.scaler.fit_transform(X)
                self.gp_regressor.fit(X_scaled, y)
                
                # å¯»æ‰¾æœ€ä¼˜ç‚¹
                best_params = None
                best_predicted = -np.inf
                
                for _ in range(100):  # éšæœºæœç´¢æœ€ä¼˜é‡‡æ ·ç‚¹
                    candidate = []
                    for j, param_name in enumerate(param_names):
                        low, high = param_bounds[j]
                        candidate.append(np.random.uniform(low, high))
                    
                    candidate_scaled = self.scaler.transform([candidate])
                    predicted_score, std = self.gp_regressor.predict(candidate_scaled, return_std=True)
                    
                    # é‡‡é›†å‡½æ•°ï¼šå¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨
                    acquisition = predicted_score[0] + 2.0 * std[0]  # Upper Confidence Bound
                    
                    if acquisition > best_predicted:
                        best_predicted = acquisition
                        best_params = dict(zip(param_names, candidate))
                
                params = best_params
            
            # è½¬æ¢ä¸ºæ•´æ•°å‚æ•°
            for param_name, param_range in param_ranges.items():
                if isinstance(param_range, range):
                    params[param_name] = int(round(params[param_name]))
            
            # è¯„ä¼°å‚æ•°
            score = self._evaluate_param_set(params)
            results.append((params, score))
            
            # æ›´æ–°å†å²
            param_vector = [params[name] for name in param_names]
            self.param_history.append(param_vector)
            self.score_history.append(score)
            
            if score > best_score:
                best_score = score
                print(f"ğŸš€ æ–°æœ€ä½³å¾—åˆ†: {score:.4f} | å‚æ•°: {params}")
            
            # æ—©åœæ£€æŸ¥
            if self._early_stop_check(score, best_score):
                print(f"â¹ï¸  æ—©åœè§¦å‘: ç¬¬{i+1}æ¬¡è¿­ä»£")
                break
        
        return results
    
    def _refined_search(self, best_params: Dict, param_ranges: Dict, refinement_factor: float = 0.1) -> List[Dict]:
        """
        ç²¾ç»†æœç´¢ï¼šåœ¨æœ€ä½³å‚æ•°å‘¨å›´è¿›è¡Œç²¾ç»†æœç´¢
        """
        print("ğŸ” å¼€å§‹ç²¾ç»†æœç´¢...")
        
        refined_grid = []
        
        # åœ¨æœ€ä½³å‚æ•°å‘¨å›´åˆ›å»ºæ›´å¯†é›†çš„ç½‘æ ¼
        for _ in range(20):  # ç”Ÿæˆ20ä¸ªç²¾ç»†æœç´¢ç‚¹
            refined_params = {}
            
            for param_name, best_value in best_params.items():
                param_range = param_ranges[param_name]
                
                if isinstance(param_range, range):
                    # æ•´æ•°å‚æ•°
                    range_size = max(param_range) - min(param_range)
                    variation = max(1, int(range_size * refinement_factor))
                    
                    new_value = best_value + np.random.randint(-variation, variation + 1)
                    new_value = max(min(param_range), min(max(param_range), new_value))
                    
                    refined_params[param_name] = new_value
                else:
                    # å…¶ä»–ç±»å‹å‚æ•°ï¼Œéšæœºé€‰æ‹©é‚»è¿‘å€¼
                    if isinstance(param_range, (list, tuple)):
                        current_idx = param_range.index(best_value) if best_value in param_range else 0
                        variation = max(1, len(param_range) // 10)
                        
                        new_idx = current_idx + np.random.randint(-variation, variation + 1)
                        new_idx = max(0, min(len(param_range) - 1, new_idx))
                        
                        refined_params[param_name] = param_range[new_idx]
                    else:
                        refined_params[param_name] = best_value
            
            refined_grid.append(refined_params)
        
        return refined_grid
    
    def optimize(self, 
                 param_ranges: Dict,
                 optimization_method: str = 'hybrid',
                 n_initial: int = 20,
                 n_bayesian: int = 30,
                 n_refined: int = 20) -> pd.DataFrame:
        """
        ä¸»ä¼˜åŒ–å‡½æ•°
        
        Parameters:
        -----------
        param_ranges : å‚æ•°èŒƒå›´å­—å…¸
        optimization_method : ä¼˜åŒ–æ–¹æ³• ('grid', 'bayesian', 'hybrid')
        n_initial : åˆå§‹ç½‘æ ¼æœç´¢ç‚¹æ•°
        n_bayesian : è´å¶æ–¯ä¼˜åŒ–è¿­ä»£æ•°
        n_refined : ç²¾ç»†æœç´¢ç‚¹æ•°
        
        Returns:
        --------
        results_df : ä¼˜åŒ–ç»“æœDataFrame
        """
        print("ğŸš€ å¯åŠ¨é«˜æ€§èƒ½å‚æ•°ä¼˜åŒ–")
        print("=" * 80)
        
        self.performance_stats['start_time'] = time.time()
        all_results = []
        
        if optimization_method in ['grid', 'hybrid']:
            # ===== ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½ç½‘æ ¼æœç´¢ =====
            phase_start = time.time()
            print(f"ğŸ“Š ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½ç½‘æ ¼æœç´¢ ({n_initial} ä¸ªç‚¹)")
            
            smart_grid = self._generate_smart_grid(param_ranges, n_initial)
            
            for i, params in enumerate(tqdm(smart_grid, desc="ç½‘æ ¼æœç´¢")):
                score = self._evaluate_param_set(params)
                all_results.append({
                    'phase': 'grid',
                    'iteration': i,
                    'params': params,
                    'score': score,
                    **params
                })
            
            self.performance_stats['phase_times']['grid'] = time.time() - phase_start
            print(f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œè€—æ—¶: {self.performance_stats['phase_times']['grid']:.2f}ç§’")
        
        if optimization_method in ['bayesian', 'hybrid'] and SKLEARN_AVAILABLE:
            # ===== ç¬¬äºŒé˜¶æ®µï¼šè´å¶æ–¯ä¼˜åŒ– =====
            phase_start = time.time()
            print(f"ğŸ§  ç¬¬äºŒé˜¶æ®µï¼šè´å¶æ–¯ä¼˜åŒ– ({n_bayesian} æ¬¡è¿­ä»£)")
            
            bayesian_results = self._bayesian_optimization(param_ranges, n_bayesian)
            
            for i, (params, score) in enumerate(bayesian_results):
                all_results.append({
                    'phase': 'bayesian',
                    'iteration': i,
                    'params': params,
                    'score': score,
                    **params
                })
            
            self.performance_stats['phase_times']['bayesian'] = time.time() - phase_start
            print(f"âœ… ç¬¬äºŒé˜¶æ®µå®Œæˆï¼Œè€—æ—¶: {self.performance_stats['phase_times']['bayesian']:.2f}ç§’")
        
        if optimization_method in ['hybrid'] and all_results:
            # ===== ç¬¬ä¸‰é˜¶æ®µï¼šç²¾ç»†æœç´¢ =====
            phase_start = time.time()
            print(f"ğŸ” ç¬¬ä¸‰é˜¶æ®µï¼šç²¾ç»†æœç´¢ ({n_refined} ä¸ªç‚¹)")
            
            # æ‰¾åˆ°å½“å‰æœ€ä½³å‚æ•°
            best_result = max(all_results, key=lambda x: x['score'])
            best_params = best_result['params']
            
            refined_grid = self._refined_search(best_params, param_ranges)
            
            for i, params in enumerate(tqdm(refined_grid, desc="ç²¾ç»†æœç´¢")):
                score = self._evaluate_param_set(params)
                all_results.append({
                    'phase': 'refined',
                    'iteration': i,
                    'params': params,
                    'score': score,
                    **params
                })
            
            self.performance_stats['phase_times']['refined'] = time.time() - phase_start
            print(f"âœ… ç¬¬ä¸‰é˜¶æ®µå®Œæˆï¼Œè€—æ—¶: {self.performance_stats['phase_times']['refined']:.2f}ç§’")
        
        # ===== ç»“æœå¤„ç†å’Œä¿å­˜ =====
        results_df = pd.DataFrame(all_results)
        results_df = results_df.sort_values('score', ascending=False).reset_index(drop=True)
        
        # ä¿å­˜ç»“æœ
        self._save_results(results_df)
        
        # æ€§èƒ½æŠ¥å‘Š
        self._print_performance_report()
        
        return results_df
    
    def _save_results(self, results_df: pd.DataFrame):
        """
        ä¿å­˜ä¼˜åŒ–ç»“æœ
        """
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_path = os.path.join(self.run_dir, 'detailed_results.csv')
        results_df.to_csv(results_path, index=False)
        
        # ä¿å­˜æœ€ä½³å‚æ•°
        best_params = results_df.iloc[0]
        best_params_path = os.path.join(self.run_dir, 'best_parameters.txt')
        
        with open(best_params_path, 'w', encoding='utf-8') as f:
            f.write("ğŸ† æœ€ä½³å‚æ•°ç»„åˆ\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç»¼åˆå¾—åˆ†: {best_params['score']:.4f}\n")
            f.write(f"ä¼˜åŒ–é˜¶æ®µ: {best_params['phase']}\n\n")
            f.write("å‚æ•°è®¾ç½®:\n")
            f.write("-" * 30 + "\n")
            
            for key, value in best_params['params'].items():
                f.write(f"{key}: {value}\n")
        
        # ä¿å­˜æ€§èƒ½ç»Ÿè®¡
        stats_path = os.path.join(self.run_dir, 'performance_stats.json')
        import json
        with open(stats_path, 'w') as f:
            json.dump(self.performance_stats, f, indent=2, default=str)
        
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {self.run_dir}")
    
    def _print_performance_report(self):
        """
        æ‰“å°æ€§èƒ½æŠ¥å‘Š
        """
        total_time = time.time() - self.performance_stats['start_time']
        
        print("\n" + "=" * 80)
        print("ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š")
        print("=" * 80)
        
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
        print(f"ğŸ¯ æ€»å›æµ‹æ¬¡æ•°: {self.performance_stats['total_backtests']}")
        print(f"ğŸ’¾ ç¼“å­˜å‘½ä¸­: {self.performance_stats['cache_hits']}")
        print(f"â¹ï¸  æ—©åœæ¬¡æ•°: {self.performance_stats['early_stops']}")
        
        if self.performance_stats['total_backtests'] > 0:
            avg_time = total_time / self.performance_stats['total_backtests']
            print(f"âš¡ å¹³å‡æ¯æ¬¡å›æµ‹: {avg_time:.4f} ç§’")
        
        print("\nğŸ”„ å„é˜¶æ®µè€—æ—¶:")
        for phase, duration in self.performance_stats['phase_times'].items():
            print(f"  ğŸ“ˆ {phase}: {duration:.2f} ç§’")
        
        print("\nğŸš€ æ€§èƒ½æå‡è¦ç‚¹:")
        print("  âœ… æ™ºèƒ½å‚æ•°ç½‘æ ¼ - å‡å°‘æ— æ•ˆæœç´¢")
        print("  âœ… è´å¶æ–¯ä¼˜åŒ– - æ™ºèƒ½å‚æ•°é€‰æ‹©")
        print("  âœ… åˆ†å±‚æœç´¢ - ç²—æœç´¢ + ç²¾ç»†ä¼˜åŒ–")
        print("  âœ… ç¼“å­˜æœºåˆ¶ - é¿å…é‡å¤è®¡ç®—")
        print("  âœ… æ—©åœç­–ç•¥ - å¿«é€Ÿæ’é™¤å·®å‚æ•°")
        print("  âœ… å¹¶è¡Œå¤„ç† - å¤šæ ¸å……åˆ†åˆ©ç”¨")
        
        cache_rate = self.performance_stats['cache_hits'] / max(1, self.performance_stats['total_backtests'])
        print(f"\nğŸ’¡ ç¼“å­˜å‘½ä¸­ç‡: {cache_rate:.1%}")
        print("=" * 80)


def run_advanced_optimization():
    """
    è¿è¡Œé«˜æ€§èƒ½å‚æ•°ä¼˜åŒ–ç¤ºä¾‹
    """
    # è®¾ç½®è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(script_dir, '..', 'tushare_data', 'daily')
    results_dir = os.path.join(script_dir, '..', 'results', 'uptrend_quantifier_advanced')
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(results_dir, exist_ok=True)
    
    # å¯¼å…¥ç­–ç•¥
    from trading.uptrend_quantifier_strategy.uptrend_quantifier_strategy import UptrendQuantifierStrategy
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = AdvancedParameterOptimizer(
        strategy_class=UptrendQuantifierStrategy,
        data_dir=data_dir,
        results_dir=results_dir,
        start_date='2021-01-01',
        end_date='2025-07-08'
    )
    
    # å®šä¹‰å‚æ•°èŒƒå›´ï¼ˆä¼˜åŒ–åçš„æ™ºèƒ½èŒƒå›´ï¼‰
    param_ranges = {
        'len_short': range(10, 31, 2),      # æ›´å¯†é›†çš„çŸ­æœŸEMA
        'len_mid': range(35, 66, 3),        # æ›´å¯†é›†çš„ä¸­æœŸEMA
        'len_long': range(150, 221, 5),     # é€‚å½“çš„é•¿æœŸEMA
        'adx_len': range(10, 21, 1),        # ç²¾ç¡®çš„ADXé•¿åº¦
        'adx_threshold': range(18, 33, 1),  # ç²¾ç¡®çš„ADXé˜ˆå€¼
    }
    
    print("ğŸ¯ å‚æ•°èŒƒå›´:")
    for param, values in param_ranges.items():
        print(f"  {param}: {list(values)[:5]}...{list(values)[-2:]} ({len(list(values))} ä¸ªå€¼)")
    
    # è¿è¡Œä¼˜åŒ–
    results = optimizer.optimize(
        param_ranges=param_ranges,
        optimization_method='hybrid',  # æ··åˆä¼˜åŒ–ç­–ç•¥
        n_initial=25,      # åˆå§‹ç½‘æ ¼ç‚¹æ•°
        n_bayesian=40,     # è´å¶æ–¯ä¼˜åŒ–è¿­ä»£æ•°  
        n_refined=15       # ç²¾ç»†æœç´¢ç‚¹æ•°
    )
    
    # æ˜¾ç¤ºæœ€ä½³ç»“æœ
    print("\nğŸ† ä¼˜åŒ–ç»“æœæ€»ç»“:")
    print("=" * 60)
    print(results[['phase', 'score'] + list(param_ranges.keys())].head(10))
    
    return results


if __name__ == "__main__":
    results = run_advanced_optimization() 